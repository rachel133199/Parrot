{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel \n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_LIST = 'top_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521\n",
      "{'AA': 0, 'AE': 1, 'AH': 2, 'AO': 3, 'AW': 4, 'AY': 5, 'B': 6, 'CH': 7, 'D': 8, 'DH': 9, 'EH': 10, 'ER': 11, 'EY': 12, 'F': 13, 'G': 14, 'HH': 15, 'IH': 16, 'IY': 17, 'JH': 18, 'K': 19, 'L': 20, 'M': 21, 'N': 22, 'NG': 23, 'OW': 24, 'OY': 25, 'P': 26, 'R': 27, 'S': 28, 'SH': 29, 'T': 30, 'TH': 31, 'UH': 32, 'UW': 33, 'V': 34, 'W': 35, 'Y': 36, 'Z': 37, 'ZH': 38}\n",
      "{0: 'AA', 1: 'AE', 2: 'AH', 3: 'AO', 4: 'AW', 5: 'AY', 6: 'B', 7: 'CH', 8: 'D', 9: 'DH', 10: 'EH', 11: 'ER', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IH', 17: 'IY', 18: 'JH', 19: 'K', 20: 'L', 21: 'M', 22: 'N', 23: 'NG', 24: 'OW', 25: 'OY', 26: 'P', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'TH', 32: 'UH', 33: 'UW', 34: 'V', 35: 'W', 36: 'Y', 37: 'Z', 38: 'ZH'}\n"
     ]
    }
   ],
   "source": [
    "PHONEMES = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH']\n",
    "phoneme_to_idx = {p:i for i, p in enumerate(PHONEMES)}\n",
    "idx_to_phoneme = {i:p for i, p in enumerate(PHONEMES)}\n",
    "\n",
    "pairs = []\n",
    "for p1 in PHONEMES:\n",
    "    for p2 in PHONEMES:\n",
    "        pairs.append((p1,p2))\n",
    "        \n",
    "print(len(pairs))\n",
    "print(phoneme_to_idx)\n",
    "print(idx_to_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse text file and create CSV\n",
    "def parse_line(line):\n",
    "    line = line.strip()\n",
    "    parts = line.split('\\t')\n",
    "    assert len(parts) == 2 # testing\n",
    "    phonemes = []\n",
    "    for phoneme in parts[1].split(' '):\n",
    "        phonemes.append(phoneme.strip('012')) # remove stress numbers\n",
    "    parts[1] = phonemes\n",
    "    return parts\n",
    "\n",
    "\n",
    "def get_phoneme_vector(phonemes: List[str]) -> List[int]:\n",
    "    vector = [0 for i in range(len(PHONEMES))]\n",
    "    for p in phonemes:\n",
    "        idx = phoneme_to_idx[p]\n",
    "        vector[idx] = 1\n",
    "    return vector\n",
    "\n",
    "with open('{}.txt'.format(WORD_LIST)) as source:\n",
    "    with open('{}.csv'.format(WORD_LIST), 'w') as dest:\n",
    "        heading = 'word,phonemes\\n'\n",
    "        dest.write(heading)\n",
    "        for line in source.readlines():\n",
    "            parts = parse_line(line)\n",
    "            #phoneme_vector = [str(i) for i in get_phoneme_vector(parts[1])]\n",
    "            l = parts[0].upper() + ',' + ' '.join(parts[1]) + '\\n'\n",
    "            dest.write(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self):\n",
    "        self.performance = [0 for i in range(39)]\n",
    "        self.counts = [0 for i in range(39)]\n",
    "        self.window = 10 # change to class variable?\n",
    "    def update_performance(self, new_score: int, phoneme_idx: int):\n",
    "        \"\"\"\n",
    "        Estimate exponential moving average\n",
    "        Source: https://stackoverflow.com/questions/12636613/how-to-calculate-moving-average-without-keeping-the-count-and-data-total\n",
    "        \"\"\"\n",
    "        if self.counts[phoneme_idx] < self.window:\n",
    "            self.counts[phoneme_idx] += 1\n",
    "        self.performance[phoneme_idx] = self.performance[phoneme_idx] + (new_score - self.performance[phoneme_idx]) / min(self.window, self.counts[phoneme_idx])\n",
    "    \n",
    "user = User()\n",
    "\n",
    "\n",
    "#user.update_performance(50, 0)\n",
    "#print(user.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarity matrix\n",
    "\n",
    "ds = pd.read_csv('{}.csv'.format(WORD_LIST))\n",
    "cf = CountVectorizer(analyzer='word', binary=True, ngram_range=(1, 2))\n",
    "count_matrix = cf.fit_transform(ds['phonemes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n"
     ]
    }
   ],
   "source": [
    "cosine_similarities = linear_kernel(count_matrix, count_matrix)\n",
    "similar_words = {}\n",
    "for idx, row in ds.iterrows():\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)\n",
    "    sorted_indices = cosine_similarities[idx].argsort()[:-100:-1] # Take only top 100\n",
    "    sorted_words = []\n",
    "    for i in sorted_indices:\n",
    "        if str(ds['word'][i]) != str(row['word']):\n",
    "            sorted_words.append((cosine_similarities[idx][i], ds['word'][i]))\n",
    "    similar_words[row['word']] = sorted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "property [(5.0, 'PROPERLY'), (5.0, 'POVERTY'), (4.0, 'CONTROVERSY'), (4.0, 'OPPORTUNITY'), (3.0, 'WORRIED'), (3.0, 'LIBERTY'), (3.0, 'ANNIVERSARY'), (3.0, 'STARTER'), (3.0, 'SCHOLARSHIP'), (3.0, 'FIRMLY')]\n",
      "\n",
      "\n",
      "area [(5.0, 'ANYBODY'), (5.0, 'VARIABLE'), (5.0, 'VARIOUS'), (5.0, 'EVERYONE'), (4.0, 'NECESSARY'), (4.0, 'VARIATION'), (4.0, 'SECRETARY'), (4.0, 'ORDINARY'), (4.0, 'COMMENTARY'), (4.0, 'ASSEMBLY')]\n",
      "\n",
      "\n",
      "quote [(1.0, 'ROSE'), (1.0, 'ROW'), (1.0, 'HORMONE'), (1.0, 'SUPPOSE'), (1.0, 'COASTAL'), (1.0, 'OWNER'), (1.0, 'HOUSEHOLD'), (1.0, 'VOTER'), (1.0, 'POEM'), (1.0, 'MOMENTUM')]\n",
      "\n",
      "\n",
      "apple [(3.0, 'CLASSIFY'), (3.0, 'ANNIVERSARY'), (3.0, 'SATELLITE'), (3.0, 'GALLON'), (3.0, 'SAMPLE'), (3.0, 'ANALYST'), (3.0, 'CAMPUS'), (3.0, 'RANDOM'), (3.0, 'STRATEGY'), (3.0, 'RAPIDLY')]\n",
      "\n",
      "\n",
      "student [(3.0, 'COMMUNICATE'), (3.0, 'COMMUNICATION'), (3.0, 'UNIFORM'), (3.0, 'UNIVERSE'), (3.0, 'BEAUTIFUL'), (3.0, 'RITUAL'), (3.0, 'SPIRITUAL'), (3.0, 'UNION'), (3.0, 'APPROVAL'), (3.0, 'USEFUL')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def top_n_similar_words(word, n):\n",
    "    return similar_words[word.upper()][:n]\n",
    "\n",
    "test_words = ['property', 'area', 'quote', 'apple', 'student']\n",
    "\n",
    "for w in test_words:\n",
    "    print(w, top_n_similar_words(w, 10))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['similar_words_top_all.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(similar_words, 'similar_words_{}.joblib'.format(WORD_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
